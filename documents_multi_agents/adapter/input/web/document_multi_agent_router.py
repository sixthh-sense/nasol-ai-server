from fastapi import APIRouter, Depends, UploadFile, HTTPException, Form, Response, Header, Request
from openai import OpenAI
from pypdf import PdfReader
import asyncio
import io
import re
import uuid

from config.crypto import Crypto
from config.redis_config import get_redis
from account.adapter.input.web.session_helper import get_current_user
from util.security.crsf import  verify_csrf_token

from documents_multi_agents.adapter.input.web.request.insert_income_request import InsertDocumentRequest
from documents_multi_agents.domain.service.prompt_templates import PromptTemplates
from util.log.log import Log
from util.cache.ai_cache import AICache

log_util = Log()
logger = Log.get_logger()
documents_multi_agents_router = APIRouter(tags=["documents_multi_agents_router"])
redis_client = get_redis()
client = OpenAI()
crypto = Crypto.get_instance()
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB

# -----------------------
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
# -----------------------
def extract_text_from_pdf_clean(file_bytes: bytes) -> str:
    try:
        reader = PdfReader(io.BytesIO(file_bytes))
        texts = []
        for page in reader.pages:
            t = page.extract_text() or ""
            t = re.sub(r'\s+', ' ', t)  # ê³µë°± ì •ë¦¬
            t = re.sub(r'\d+\s*$', '', t)  # í˜ì´ì§€ ë²ˆí˜¸ ì œê±° (í–‰ ë ìˆ«ì)
            if t.strip():
                texts.append(t.strip())
        return "\n".join(texts)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"PDF parsing error: {str(e)}")


# -----------------------
# GPT í˜¸ì¶œ ë˜í¼ (ê¸°ì¡´)
# -----------------------
async def ask_gpt(prompt: str, max_tokens=500):
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, lambda:
    client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=0
    ).choices[0].message.content
                                      )


# -----------------------
# QA ì—ì´ì „íŠ¸ (ë¬¸ì„œ ê¸°ë°˜)
# -----------------------
@log_util.logging_decorator
async def qa_on_document(document: str, question: str, role: str) -> str:
    prompt = f"""
ë‹¤ìŒì€ ë¬¸ì„œ ìë£Œì´ë‹¤. ì´ ë¬¸ì„œ ë‚´ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•´ë¼.
ë‹µë³€ ì‹œ ì¡´ëŒ“ë§ ì‚¬ìš©ì„ ìœ ì§€í•´ë¼.

ìš”ì•½:
{document}

ì§ˆë¬¸:
{question}

ê·œì¹™:
{role}
"""
    return (await ask_gpt(prompt, max_tokens=2500)).strip()


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸
# -----------------------
@documents_multi_agents_router.post("/analyze")
@log_util.logging_decorator
async def analyze_document(
        request: Request,
        response: Response,
        file: UploadFile,
        type_of_doc: str = Form(...),
        session_id: str = Depends(get_current_user),
        x_csrf_token:  str | None = Header(None)
):
    # CSRF ê²€ì¦
    verify_csrf_token(request, x_csrf_token)

    try:
        # ì¿ í‚¤ì— session_id ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        response.set_cookie(
            key="session_id",
            value=session_id,
            max_age=24 * 60 * 60,
            httponly=True,
            samesite="lax"
        )

        content = await file.read()
        if not content:
            raise HTTPException(400, "Empty file upload")

        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(413, "File too large")

        text = extract_text_from_pdf_clean(content)
        if not text:
            raise HTTPException(400, "No text extracted")

        logger.info(f"Extracted text length: {len(text)}")

        # 2. QA (ìš”ì•½ ê¸°ë°˜)
        # type_of_docì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
        if "ì†Œë“" in type_of_doc or "income" in type_of_doc.lower():
            extraction_question = (
                "PDFì—ì„œ ì†Œë“ ê´€ë ¨ í•­ëª©ê³¼ ê¸ˆì•¡ë§Œ ì¶”ì¶œí•´ì¤˜. "
                "ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€: í•­ëª©ëª…: ê¸ˆì•¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©) "
                "ì„¤ëª…, ì£¼ì„, ë³„í‘œ, ë§ˆí¬ë‹¤ìš´ ë“± ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ "
                "ì˜ˆì‹œ: "
                "ê¸‰ì—¬: 3000000 "
                "ì‹ëŒ€: 200000 "
                "ìƒì—¬: 500000"
            )
            extraction_role = (
                "ì†Œë“ í•­ëª©ë§Œ í¬í•¨: ê¸‰ì—¬, ìƒì—¬, ì‹ëŒ€, ìˆ˜ë‹¹, ì´ê¸‰ì—¬, ì´ìì†Œë“, ë°°ë‹¹ì†Œë“ "
                "ì ˆëŒ€ ì œì™¸: ë³´í—˜ë£Œ, ì„¸ê¸ˆ, ê³µì œì•¡ ë“± ì°¨ê°/ì§€ì¶œ í•­ëª© "
                "ì¶”ë¡  ê¸ˆì§€, ë¬¸ì„œ ë‚´ ë°ì´í„°ë§Œ ì‚¬ìš© "
                "ì›”ë³„ êµ¬ë¶„ ìˆìœ¼ë©´ í•©ê³„ë§Œ ì‚¬ìš© "
                "ì„¤ëª…ë¬¸, ì£¼ì„ ì ˆëŒ€ ê¸ˆì§€ - ìˆœìˆ˜ ë°ì´í„°ë§Œ ë°˜í™˜"
            )
        elif "ì§€ì¶œ" in type_of_doc or "expense" in type_of_doc.lower():
            extraction_question = (
                "PDFì—ì„œ ì§€ì¶œ ê´€ë ¨ í•­ëª©ê³¼ ê¸ˆì•¡ë§Œ ì¶”ì¶œí•´ì¤˜. "
                "ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€: í•­ëª©ëª…: ê¸ˆì•¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©) "
                "ì„¤ëª…, ì£¼ì„, ë³„í‘œ, ë§ˆí¬ë‹¤ìš´ ë“± ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ "
                "ì˜ˆì‹œ: "
                "êµ­ë¯¼ì—°ê¸ˆë³´í—˜ë£Œ: 500000 "
                "ì‹ ìš©ì¹´ë“œ: 1000000 "
                "ê±´ê°•ë³´í—˜ë£Œ: 300000"
            )
            extraction_role = (
                "ì§€ì¶œ í•­ëª©ë§Œ í¬í•¨: ë³´í—˜ë£Œ, ì¹´ë“œì‚¬ìš©ì•¡, ì„¸ê¸ˆ, ê³µê³¼ê¸ˆ, ëŒ€ì¶œ, ì›”ì„¸, í†µì‹ ë¹„ "
                "ì ˆëŒ€ ì œì™¸: ê¸‰ì—¬, ì†Œë“, ìˆ˜ë‹¹ ë“± ìˆ˜ì… í•­ëª© "
                "ì¶”ë¡  ê¸ˆì§€, ë¬¸ì„œ ë‚´ ë°ì´í„°ë§Œ ì‚¬ìš© "
                "ì›”ë³„ êµ¬ë¶„ ìˆìœ¼ë©´ í•©ê³„ë§Œ ì‚¬ìš© "
                "ì„¤ëª…ë¬¸, ì£¼ì„ ì ˆëŒ€ ê¸ˆì§€ - ìˆœìˆ˜ ë°ì´í„°ë§Œ ë°˜í™˜"
            )
        else:
            # íƒ€ì…ì„ ëª¨ë¥¼ ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
            extraction_question = (
                "PDFì˜ í•­ëª©ê³¼ ê¸ˆì•¡ì„ ì¶”ì¶œí•´ì¤˜. "
                "í˜•ì‹: í•­ëª©ëª…: ê¸ˆì•¡ (í•œ ì¤„ì— í•˜ë‚˜ì”©)"
            )
            extraction_role = (
                "ë¬¸ì„œ ë‚´ ëª¨ë“  ê¸ˆì•¡ ì°¾ê¸° "
                "ì›”ë³„ êµ¬ë¶„ ìˆìœ¼ë©´ í•©ê³„ë§Œ ì‚¬ìš© "
                "ì„¤ëª…ë¬¸ ê¸ˆì§€ - ìˆœìˆ˜ ë°ì´í„°ë§Œ"
            )

        answer = await qa_on_document(text, extraction_question, extraction_role)

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")  # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        pattern = re.compile(r'([ê°€-í£\w\s]+)\s*:\s*([\d,]+)')
        matches = list(pattern.finditer(answer))

        logger.info(f"[DEBUG] Pattern matches found: {len(matches)}")

        # ì¶”ì¶œëœ í•­ëª©ë“¤ì„ ì €ì¥í•˜ê³  ë™ì‹œì— ìˆ˜ì§‘
        extracted_items = {}
        duplicate_keywords = ["ì´ê¸‰ì—¬", "ì´ì†Œë“", "í•©ê³„", "ì´í•©", "ì´ì•¡"]  # ì¤‘ë³µ ê°€ëŠ¥ì„± ìˆëŠ” í‚¤ì›Œë“œ

        try:
            for match in matches:
                field, value = match.groups()
                field_clean = field.strip()
                value_clean = value.replace(",", "").strip()

                # ì¤‘ë³µ ì²´í¬: ê°™ì€ ê¸ˆì•¡ì˜ ìœ ì‚¬ í•­ëª©ì´ ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ
                is_duplicate = False
                for existing_field, existing_value in extracted_items.items():
                    if value_clean == existing_value:  # ê¸ˆì•¡ì´ ê°™ê³ 
                        # í•˜ë‚˜ê°€ ë‹¤ë¥¸ í•˜ë‚˜ì˜ "í•©ê³„" ë²„ì „ì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                        if any(keyword in field_clean for keyword in duplicate_keywords) or \
                                any(keyword in existing_field for keyword in duplicate_keywords):
                            is_duplicate = True
                            logger.info(f"[DEBUG] Duplicate found: {field_clean} ")
                            break

                if is_duplicate:
                    continue

                # ì•”í˜¸í™”ëœ í‚¤/ê°’ ìƒì„±
                encrypted_key = crypto.enc_data(f"{type_of_doc}:{field_clean}")
                encrypted_value = crypto.enc_data(value_clean)

                # Redisì— ì €ì¥
                redis_client.hset(
                    session_id,
                    encrypted_key,
                    encrypted_value
                )

                # ì €ì¥ í™•ì¸
                saved_value = redis_client.hget(session_id, encrypted_key)
                logger.info(f"Saved successfully: {saved_value is not None}")

                # ì‘ë‹µìš© ë°ì´í„° ìˆ˜ì§‘
                extracted_items[field_clean] = value_clean

        except Exception as e:
            logger.error(f"[ERROR] Failed to save to Redis: {str(e)}")
            import traceback
            traceback.print_exc()

        redis_client.expire(session_id, 24 * 60 * 60)

        # ğŸ”¥ ìƒˆ ë¬¸ì„œ ì—…ë¡œë“œ ì‹œ ê¸°ì¡´ ìºì‹œ ë¬´íš¨í™”
        # ì‚¬ìš©ì ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ ëª¨ë“  AI ë¶„ì„ ìºì‹œë¥¼ ì œê±°
        logger.info(f"Invalidating cache for session: {session_id}")
        invalidated_count = AICache.invalidate_user_cache(session_id)
        logger.info(f"Invalidated {invalidated_count} cache entries")

        logger.info(f"[DEBUG] Extracted items: {len(extracted_items)}")

        if not extracted_items:
            logger.warning("No items were extracted from PDF!")
            return {
                "success": False,
                "message": "PDFì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PDF í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                "session_id": session_id,
                "document_type": type_of_doc,
                "extracted_count": 0,
                "categorized_data": {}
            }

        # AIë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        from documents_multi_agents.domain.service.financial_analyzer_service import FinancialAnalyzerService

        analyzer = FinancialAnalyzerService()

        # type_of_docì— ë”°ë¼ ì†Œë“/ì§€ì¶œ ë¶„ë¥˜
        categorized_data = {}
        if "ì†Œë“" in type_of_doc or "income" in type_of_doc.lower():
            categorized_data = analyzer._categorize_income(extracted_items)
        elif "ì§€ì¶œ" in type_of_doc or "expense" in type_of_doc.lower():
            categorized_data = analyzer._categorize_expense(extracted_items)
        else:
            # íƒ€ì…ì„ ëª¨ë¥¼ ê²½ìš° ì›ë³¸ ë°ì´í„°ë§Œ ë°˜í™˜
            categorized_data = {"raw_items": extracted_items}

        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜ (session_id í¬í•¨)
        return {
            "success": True,
            "message": "ë¶„ì„ ì™„ë£Œ",
            "session_id": session_id,  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª…ì‹œì ìœ¼ë¡œ ë°˜í™˜
            "document_type": type_of_doc,
            "extracted_count": len(extracted_items),
            "categorized_data": categorized_data
        }

    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ë¯¸ë˜ ìì‚° ì˜ˆì¸¡
# -----------------------
@documents_multi_agents_router.get("/future-assets")
@log_util.logging_decorator
async def analyze_document(session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)
        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(k_bytes)
                val_plain = crypto.dec_data(v_bytes)

                # key_plainì€ "type:field" í˜•íƒœ â€” ì›í•˜ëŠ” ëŒ€ë¡œ ì²˜ë¦¬
                _, field_name = key_plain.split(':', 1)
                pairs.append(f"{field_name}: {val_plain}")

            except ValueError as e:
                # ë³µí˜¸í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…/ë¬´ì‹œ
                continue

        data_str = ", ".join(pairs)

        # ğŸ”¥ ìºì‹œ í™•ì¸
        cache_key = AICache.generate_cache_key(data_str, "future-assets")
        cached_response = AICache.get_cached_response(cache_key)

        if cached_response:
            return cached_response

        # ìºì‹œ ë¯¸ìŠ¤ - GPT í˜¸ì¶œ
        question, role = PromptTemplates.get_future_assets_prompt()
        answer = await qa_on_document(data_str, question, role)

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")   # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        # ğŸ”¥ ìºì‹œ ì €ì¥ (24ì‹œê°„)
        AICache.set_cached_response(cache_key, answer, ttl=86400)

        return answer
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ì„¸ì•¡ ê³µì œ í™•ì¸
# -----------------------
@documents_multi_agents_router.get("/tax-credit")
@log_util.logging_decorator
async def analyze_document(session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)
        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(k_bytes)
                val_plain = crypto.dec_data(v_bytes)

                # key_plainì€ "type:field" í˜•íƒœ â€” ì›í•˜ëŠ” ëŒ€ë¡œ ì²˜ë¦¬
                _, field_name = key_plain.split(':', 1)
                pairs.append(f"{field_name}: {val_plain}")

            except ValueError as e:
                # ë³µí˜¸í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…/ë¬´ì‹œ
                continue

        data_str = ", ".join(pairs)

        # ğŸ”¥ ìºì‹œ í™•ì¸
        cache_key = AICache.generate_cache_key(data_str, "tax-credit")
        cached_response = AICache.get_cached_response(cache_key)

        if cached_response:
            return cached_response

        # ìºì‹œ ë¯¸ìŠ¤ - GPT í˜¸ì¶œ
        question, role = PromptTemplates.get_tax_credit_prompt()
        answer = await qa_on_document(data_str, question, role)

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")   # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        # ğŸ”¥ ìºì‹œ ì €ì¥ (24ì‹œê°„)
        AICache.set_cached_response(cache_key, answer, ttl=86400)

        return answer
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ì—°ë§ì •ì‚° ê³µì œ ë‚´ì—­ í™•ì¸
# -----------------------
@documents_multi_agents_router.get("/deduction-expectation")
@log_util.logging_decorator
async def analyze_document(session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)
        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(k_bytes)
                val_plain = crypto.dec_data(v_bytes)

                # key_plainì€ "type:field" í˜•íƒœ â€” ì›í•˜ëŠ” ëŒ€ë¡œ ì²˜ë¦¬
                _, field_name = key_plain.split(':', 1)
                pairs.append(f"{field_name}: {val_plain}")

            except ValueError as e:
                # ë³µí˜¸í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…/ë¬´ì‹œ
                continue

        data_str = ", ".join(pairs)

        # ğŸ”¥ ìºì‹œ í™•ì¸
        cache_key = AICache.generate_cache_key(data_str, "deduction-expectation")
        cached_response = AICache.get_cached_response(cache_key)

        if cached_response:
            return cached_response

        # ìºì‹œ ë¯¸ìŠ¤ - GPT í˜¸ì¶œ
        question, role = PromptTemplates.get_deduction_expectation_prompt()
        answer = await qa_on_document(data_str, question, role)

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")   # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        # ğŸ”¥ ìºì‹œ ì €ì¥ (24ì‹œê°„)
        AICache.set_cached_response(cache_key, answer, ttl=86400)

        return answer
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸
# ëª©í‘œ ê¸ˆì•¡ ì¬ë¬´ ê°€ì´ë“œ
# -----------------------
@documents_multi_agents_router.get("/deduction-expectation")
@log_util.logging_decorator
async def analyze_document(session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)
        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(k_bytes)
                val_plain = crypto.dec_data(v_bytes)

                # key_plainì€ "type:field" í˜•íƒœ â€” ì›í•˜ëŠ” ëŒ€ë¡œ ì²˜ë¦¬
                _, field_name = key_plain.split(':', 1)
                pairs.append(f"{field_name}: {val_plain}")

            except ValueError as e:
                # ë³µí˜¸í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…/ë¬´ì‹œ
                continue

        data_str = ", ".join(pairs)

        answer = await qa_on_document(data_str,
                                      "ì£¼ì–´ì§„ ë¬¸ì„œ ë³¸ë¬¸ì„ í™œìš©í•˜ì—¬ ì—°ë§ì •ì‚°ì—ì„œ ë°›ì„ ìˆ˜ ìˆëŠ” ì´ ê³µì œ ì˜ˆìƒ ê¸ˆì•¡ì„ ì‚°ì¶œí•´ì¤˜. "
                                      "ì´ ë•Œ ë‚´ê°€ ë°›ì„ ìˆ˜ ìˆëŠ” ì´ ê³µì œ ì˜ˆìƒ ê¸ˆì•¡ì„ ë¨¼ì € ì‚°ì¶œí•´ì„œ ë³´ì—¬ì£¼ê³ , "
                                      "ì•ìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆëŠ” ì¶”ê°€ì ì¸ ê³µì œë‚´ì—­ì´ ìˆë‹¤ë©´ í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì•Œë ¤ì¤˜."
                                      "ì°¸ê³ í•  ì‚¬ì´íŠ¸ëŠ” https://www.nts.go.kr/nts/cm/cntnts/cntntsView.do?mi=6596&cntntsId=7875 êµ­ì„¸ì²­ ê³µì‹ ì‚¬ì´íŠ¸ì•¼",
                                      "ì£¼ì–´ì§„ ë¬¸ì„œ ë³¸ë¬¸ì˜ ìë£Œë¥¼ í† ëŒ€ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë¼."
                                      "ì¶”ê°€ì ì¸ ì§ˆë¬¸ì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì¥ì€ ì œì™¸í•˜ë¼."
                                      "-- ë“±ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì¤„ë‚˜ëˆ”ì€ ì—†ê²Œ í•˜ë¼."
                                      "ë‹µë³€ ì• ë’¤ë¡œ ìŒë”°ì›€í‘œ ê°™ì€ ê²ƒì„ ë¶™ì´ì§€ ë§ˆë¼."
                                      )

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")  # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        return answer
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")

@documents_multi_agents_router.get("/financial-guide")
@log_util.logging_decorator
async def analyze_document(now_mon: int, tar_mon: int, session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)
        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(k_bytes)
                val_plain = crypto.dec_data(v_bytes)

                # key_plainì€ "type:field" í˜•íƒœ â€” ì›í•˜ëŠ” ëŒ€ë¡œ ì²˜ë¦¬
                _, field_name = key_plain.split(':', 1)
                pairs.append(f"{field_name}: {val_plain}")

            except ValueError as e:
                # ë³µí˜¸í™” ì‹¤íŒ¨ ì‹œ ë¡œê¹…/ë¬´ì‹œ
                continue

        data_str = ", ".join(pairs)

        answer = await qa_on_document(data_str,
                                      f"ì£¼ì–´ì§„ ë¬¸ì„œ ë³¸ë¬¸ì„ í™œìš©í•˜ì—¬ í˜„ì¬ ë‚´ ìì‚°ì´ {now_mon}ì´ê³ , "
                                      f"ë‚´ê°€ ëª©í‘œë¡œ í•˜ëŠ” ê¸ˆì•¡ì´ {tar_mon}ì¼ ë•Œ"
                                      "í˜„ì¬ ìì‚°ì´ ëª©í‘œ ê¸ˆì•¡ì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ë¶„ì„ í•´ì¤˜. "
                                      "ì´ ë•Œ ëª©í‘œë¥¼ ë‹¨ê¸°, ì¤‘ê¸°, ì¥ê¸° ëª©í‘œë¡œ ë‚˜ëˆ„ê³  "
                                      "ê° ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ ë¦¬ìŠ¤í¬ê°€ ì—†ëŠ” ë°©ë²•, ë¦¬ìŠ¤í¬ê°€ ìˆëŠ” ë°©ë²•, ë¦¬ìŠ¤í¬ê°€ í° ë°©ë²•ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì„¤ëª…í•´ì¤˜. ",
                                      "ì£¼ì–´ì§„ ë¬¸ì„œ ë³¸ë¬¸ì˜ ìë£Œë¥¼ í† ëŒ€ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ë¼."
                                      "ì¶”ê°€ì ì¸ ì§ˆë¬¸ì„ ìš”êµ¬í•˜ëŠ” ë¬¸ì¥ì€ ì œì™¸í•˜ë¼."
                                      "-- ë“±ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì¤„ë‚˜ëˆ”ì€ ì—†ê²Œ í•˜ë¼."
                                      )

        # AI ì‘ë‹µ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´, ì„¤ëª…ë¬¸ ì œê±°
        answer = answer.replace("**", "")  # ë³¼ë“œ ì œê±°
        answer = answer.replace("*", "")  # ì´íƒ¤ë¦­ ì œê±°
        answer = re.sub(r'â€».*', '', answer)  # ì£¼ì„ ì œê±°
        answer = re.sub(r'---.*', '', answer, flags=re.DOTALL)  # êµ¬ë¶„ì„  ì´í›„ ì œê±°

        return answer
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")

# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸ - ì‚¬ìš©ì ì…ë ¥ í¼ ë°ì´í„°
# -----------------------
@documents_multi_agents_router.post("/analyze_form")
@log_util.logging_decorator
async def insert_document(
        response: Response,
        request: InsertDocumentRequest,
        session_id: str = Depends(get_current_user)
):
    session_expire_seconds = 24 * 60 * 60

    try:
        # ì¿ í‚¤ì— session_id ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        response.set_cookie(
            key="session_id",
            value=session_id,
            max_age=24 * 60 * 60,
            httponly=True,
            samesite="lax"
        )

        # ì„¸ì…˜ ì²˜ë¦¬
        if not session_id:
            session_id = str(uuid.uuid4())
            redis_client.hset(session_id, "USER_TOKEN", "GUEST")
            redis_client.expire(session_id, 24 * 60 * 60)

        # ì•”í˜¸í™”í•´ì„œ ì €ì¥ ë° ë°ì´í„° ìˆ˜ì§‘
        extracted_items = {}
        for field_key, field_value in request.data.items():
            value_clean = field_value.replace(",", "").strip()

            # ì•”í˜¸í™”ëœ í‚¤/ê°’ ìƒì„±
            encrypted_key = crypto.enc_data(f"{request.document_type}:{field_key}")
            encrypted_value = crypto.enc_data(value_clean)

            redis_client.hset(
                session_id,
                encrypted_key,
                encrypted_value
            )

            # ì €ì¥ í™•ì¸
            saved_value = redis_client.hget(session_id, encrypted_key)
            logger.debug(f"[DEBUG] Saved successfully: {saved_value is not None}")

            # ì‘ë‹µìš© ë°ì´í„° ìˆ˜ì§‘
            extracted_items[field_key] = value_clean

        redis_client.expire(session_id, session_expire_seconds)

        # AIë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        from documents_multi_agents.domain.service.financial_analyzer_service import FinancialAnalyzerService

        analyzer = FinancialAnalyzerService()

        # typeì— ë”°ë¼ ì†Œë“/ì§€ì¶œ ë¶„ë¥˜
        categorized_data = {}
        if "ì†Œë“" in request.document_type or "income" in request.document_type.lower():
            categorized_data = analyzer._categorize_income(extracted_items)
        elif "ì§€ì¶œ" in request.document_type or "expense" in request.document_type.lower():
            categorized_data = analyzer._categorize_expense(extracted_items)
        else:
            categorized_data = {"raw_items": extracted_items}

        return {
            "success": True,
            "message": "ë¶„ì„ ì™„ë£Œ",
            "session_id": session_id,
            "document_type": request.document_type,
            "extracted_count": len(extracted_items),
            "categorized_data": categorized_data,
            "expire_in_seconds": session_expire_seconds
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# -----------------------
# ë””ë²„ê·¸: Redis ë°ì´í„° í™•ì¸
# -----------------------
@documents_multi_agents_router.get("/debug/redis-data")
@log_util.logging_decorator
async def debug_redis_data(session_id: str = Depends(get_current_user)):
    """Redisì— ì €ì¥ëœ ì›ë³¸ ë°ì´í„° í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    try:
        raw_data = redis_client.hgetall(session_id)

        result = {
            "session_id": session_id,
            "total_keys": len(raw_data),
            "keys": []
        }

        for key_bytes, value_bytes in raw_data.items():
            try:
                # bytesë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                if isinstance(key_bytes, bytes):
                    key_str = key_bytes.decode('utf-8')
                else:
                    key_str = str(key_bytes)

                if isinstance(value_bytes, bytes):
                    value_str = value_bytes.decode('utf-8')
                else:
                    value_str = str(value_bytes)

                # USER_TOKENì€ ì•”í˜¸í™”ë˜ì§€ ì•ŠìŒ
                if key_str == "USER_TOKEN":
                    result["keys"].append({
                        "key": key_str,
                        "value": "[REDACTED]",  # ë³´ì•ˆì„ ìœ„í•´ ìˆ¨ê¹€
                        "encrypted": False
                    })
                else:
                    # ë³µí˜¸í™” ì‹œë„
                    try:
                        decrypted_key = crypto.dec_data(key_str)
                        decrypted_value = crypto.dec_data(value_str)
                        result["keys"].append({
                            "key_encrypted": key_str[:50] + "...",
                            "key_decrypted": decrypted_key,
                            "value_decrypted": decrypted_value,
                            "encrypted": True
                        })
                    except Exception as decrypt_err:
                        result["keys"].append({
                            "key": key_str[:50] + "...",
                            "value": value_str[:50] + "...",
                            "error": f"ë³µí˜¸í™” ì‹¤íŒ¨: {str(decrypt_err)}",
                            "encrypted": False
                        })
            except Exception as e:
                result["keys"].append({
                    "error": f"í‚¤ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                })

        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# -----------------------
# í†µí•© ê²°ê³¼ ì¡°íšŒ (ì†Œë“ + ì§€ì¶œ)
# -----------------------
@documents_multi_agents_router.get("/result")
@log_util.logging_decorator
async def get_combined_result(session_id: str = Depends(get_current_user)):
    """
    Redisì— ì €ì¥ëœ ì†Œë“+ì§€ì¶œ ë°ì´í„°ë¥¼ ë³µí˜¸í™”í•˜ê³  ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•˜ì—¬ ë°˜í™˜
    ì‹œê°í™”ì— ì í•©í•œ í˜•íƒœë¡œ ë°ì´í„° êµ¬ì¡°í™”
    """
    try:
        logger.debug("[DEBUG] /result called with session_id")

        # Redisì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        encrypted_data = redis_client.hgetall(session_id)

        # ğŸ”¥ ë²„ê·¸ ìˆ˜ì •: USER_TOKENë§Œ ìˆëŠ” ê²½ìš°ë„ ë¹ˆ ë°ì´í„°ë¡œ ê°„ì£¼
        if not encrypted_data or len(encrypted_data) <= 1:
            raise HTTPException(
                status_code=404,
                detail="ì €ì¥ëœ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            )

        # ë³µí˜¸í™” ë° ì†Œë“/ì§€ì¶œ ë¶„ë¦¬
        income_items = {}
        expense_items = {}

        for key_bytes, value_bytes in encrypted_data.items():
            try:
                # bytesë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                if isinstance(key_bytes, bytes):
                    key_str = key_bytes.decode('utf-8')
                else:
                    key_str = str(key_bytes)

                if isinstance(value_bytes, bytes):
                    value_str = value_bytes.decode('utf-8')
                else:
                    value_str = str(value_bytes)

                # USER_TOKEN ì œì™¸
                if key_str == "USER_TOKEN":
                    logger.debug("[DEBUG] Skipping USER_TOKEN")
                    continue

                key_plain = crypto.dec_data(key_str)
                value_plain = crypto.dec_data(value_str)

                # "íƒ€ì…:í•„ë“œëª…" í˜•íƒœ íŒŒì‹±
                if ":" in key_plain:
                    doc_type, field_name = key_plain.split(":", 1)

                    if "ì†Œë“" in doc_type or "income" in doc_type.lower():
                        income_items[field_name] = value_plain
                    elif "ì§€ì¶œ" in doc_type or "expense" in doc_type.lower():
                        expense_items[field_name] = value_plain
            except Exception as decrypt_error:
                logger.error(
                    f"[ERROR] Decryption failed for key: {key_str[:50] if 'key_str' in locals() else 'unknown'}")
                logger.error(f"[ERROR] Error: {str(decrypt_error)}")
                import traceback
                traceback.print_exc()
                continue

        logger.debug(f"[DEBUG] Total income_items: {len(income_items)}")
        logger.debug(f"[DEBUG] Total expense_items: {len(expense_items)}")
        # ì†Œë“ í•­ëª© ì¤‘ ì§€ì¶œì„± í•­ëª©ì„ ì§€ì¶œë¡œ ì¬ë¶„ë¥˜
        # 1. ë³´í—˜ë£Œ
        insurance_keywords = ["ë³´í—˜ë£Œ", "ë³´í—˜", "ì—°ê¸ˆ"]
        # 2. ì„¸ê¸ˆ
        tax_keywords = ["ì†Œë“ì„¸", "ì§€ë°©ì†Œë“ì„¸", "ì„¸ì•¡"]

        items_to_move = []

        for field_name, value in list(income_items.items()):
            should_move = False

            # ë³´í—˜ë£Œ ê´€ë ¨ í•­ëª© ì²´í¬
            if any(keyword in field_name for keyword in insurance_keywords):
                # ê³µì œ ê¸ˆì•¡ì´ ì•„ë‹Œ ì‹¤ì œ ë³´í—˜ë£Œë§Œ ì´ë™
                if "ê³µì œ" not in field_name and "ëŒ€ìƒ" not in field_name:
                    should_move = True

            # ì„¸ê¸ˆ ê´€ë ¨ í•­ëª© ì²´í¬
            if any(keyword in field_name for keyword in tax_keywords):
                # ê³µì œ ê¸ˆì•¡ì´ ì•„ë‹Œ ì‹¤ì œ ì„¸ê¸ˆë§Œ ì´ë™
                if "ê³µì œ" not in field_name and "ê³¼ì„¸í‘œì¤€" not in field_name and "ì‚°ì¶œ" not in field_name:
                    should_move = True

            if should_move:
                items_to_move.append(field_name)

        # ì‹¤ì œ ì´ë™
        for field_name in items_to_move:
            expense_items[field_name] = income_items.pop(field_name)

        logger.debug(f"[DEBUG] After reclassification - income: {len(income_items)}, expense: {len(expense_items)}")

        # AIë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        from documents_multi_agents.domain.service.financial_analyzer_service import FinancialAnalyzerService

        analyzer = FinancialAnalyzerService()

        income_categorized = analyzer._categorize_income(income_items) if income_items else {}
        expense_categorized = analyzer._categorize_expense(expense_items) if expense_items else {}

        # ìš”ì•½ ì •ë³´ ê³„ì‚° (ì•ˆì „í•œ íƒ€ì… ë³€í™˜) - í•œê¸€ í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ë¬¸ í‚¤
        try:
            total_income = int(income_categorized.get("ì´ì†Œë“") or income_categorized.get("total_income", 0)) if (
                        income_categorized.get("ì´ì†Œë“") or income_categorized.get("total_income")) else 0
        except (ValueError, TypeError) as e:
            logger.error(f"[ERROR] Failed to calculate total_income: {e}")
            total_income = 0

        try:
            total_expense = int(expense_categorized.get("ì´ì§€ì¶œ") or expense_categorized.get("total_expense", 0)) if (
                        expense_categorized.get("ì´ì§€ì¶œ") or expense_categorized.get("total_expense")) else 0
        except (ValueError, TypeError) as e:
            logger.error(f"[ERROR] Failed to calculate total_expense: {e}")
            total_expense = 0

        surplus = total_income - total_expense
        surplus_ratio = (surplus / total_income * 100) if total_income > 0 else 0

        # ì‹œê°í™”ìš© ë°ì´í„° êµ¬ì¡°
        return {
            "success": True,
            "summary": {
                "total_income": total_income,
                "total_expense": total_expense,
                "surplus": surplus,
                "surplus_ratio": round(surplus_ratio, 2),
                "status": "í‘ì" if surplus > 0 else "ì ì" if surplus < 0 else "ìˆ˜ì§€ê· í˜•"
            },
            "income": income_categorized,
            "expense": expense_categorized,
            "chart_data": {
                "income_by_category": income_categorized.get("ì¹´í…Œê³ ë¦¬ë³„ í•©ê³„") or income_categorized.get(
                    "ì¹´í…Œê³ ë¦¬ë³„í•©ê³„") or income_categorized.get("total_by_category", {}),
                "expense_by_main_category": expense_categorized.get("ì¹´í…Œê³ ë¦¬ë³„ í•©ê³„") or expense_categorized.get(
                    "ì¹´í…Œê³ ë¦¬ë³„í•©ê³„") or expense_categorized.get("total_by_main_category", {}),
                "expense_detail": expense_categorized
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"{type(e).__name__}: {str(e)}")


# -----------------------
# API ì—”ë“œí¬ì¸íŠ¸ - ì„¸ì•¡ê³µì œ ê°€ëŠ¥ í•­ëª© ì²´í¬ë¦¬ìŠ¤íŠ¸
# -----------------------
@documents_multi_agents_router.get("/tax-credit/checklist")
async def tax_credit_checklist_markdown(session_id: str = Depends(get_current_user)):
    try:
        content = redis_client.hgetall(session_id)

        if not content:
            return "ì €ì¥ëœ ì¬ë¬´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        pairs = []
        for k_bytes, v_bytes in content.items():
            try:
                if k_bytes == "USER_TOKEN":
                    continue

                key_plain = crypto.dec_data(
                    k_bytes.decode("utf-8") if isinstance(k_bytes, bytes) else k_bytes
                )
                val_plain = crypto.dec_data(
                    v_bytes.decode("utf-8") if isinstance(v_bytes, bytes) else v_bytes
                )

                # "ì§€ì¶œ:ì›”ì„¸" â†’ ì›”ì„¸
                _, field_name = key_plain.split(":", 1)
                pairs.append(f"{field_name}: {val_plain}")

            except Exception:
                continue

        data_str = ", ".join(pairs)

        # ğŸ”¥ ìºì‹œ í™•ì¸
        cache_key = AICache.generate_cache_key(data_str, "tax-credit-checklist")
        cached_response = AICache.get_cached_response(cache_key)

        if cached_response:
            return cached_response

        # ìºì‹œ ë¯¸ìŠ¤ - GPT í˜¸ì¶œ
        tax_items_text = """
1. ìë…€ ì„¸ì•¡ê³µì œ
2. ì—°ê¸ˆê³„ì¢Œ ì„¸ì•¡ê³µì œ
3. ì›”ì„¸ ì„¸ì•¡ê³µì œ
4. ë³´í—˜ë£Œ ì„¸ì•¡ê³µì œ
5. ì˜ë£Œë¹„ ì„¸ì•¡ê³µì œ
6. êµìœ¡ë¹„ ì„¸ì•¡ê³µì œ
7. ê¸°ë¶€ê¸ˆ ì„¸ì•¡ê³µì œ
8. í˜¼ì¸ ì„¸ì•¡ê³µì œ
9. ì¤‘ì†Œê¸°ì—… ì·¨ì—…ì ì†Œë“ì„¸ ê°ë©´
10. ê·¼ë¡œì†Œë“ì„¸ì•¡ê³µì œ
"""

        question = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì œì¶œí•œ ì¬ë¬´ ìë£Œì…ë‹ˆë‹¤:

{data_str}

ì•„ë˜ 10ê°œì˜ ì„¸ì•¡ê³µì œ í•­ëª© ê°ê°ì— ëŒ€í•´ ë‹¤ìŒì„ ë¶„ì„í•˜ì„¸ìš”.

### ì„¸ì•¡ê³µì œ í•­ëª© ëª©ë¡
1. ìë…€ ì„¸ì•¡ê³µì œ
2. ì—°ê¸ˆê³„ì¢Œ ì„¸ì•¡ê³µì œ
3. ì›”ì„¸ ì„¸ì•¡ê³µì œ
4. ë³´í—˜ë£Œ ì„¸ì•¡ê³µì œ
5. ì˜ë£Œë¹„ ì„¸ì•¡ê³µì œ
6. êµìœ¡ë¹„ ì„¸ì•¡ê³µì œ
7. ê¸°ë¶€ê¸ˆ ì„¸ì•¡ê³µì œ
8. í˜¼ì¸ ì„¸ì•¡ê³µì œ
9. ì¤‘ì†Œê¸°ì—… ì·¨ì—…ì ì†Œë“ì„¸ ê°ë©´
10. ê·¼ë¡œì†Œë“ì„¸ì•¡ê³µì œ

---

# ğŸ“Œ ì¶œë ¥ í˜•ì‹ (ì•„ì£¼ ì¤‘ìš”)

ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ ë‘ ë¶€ë¶„ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.

---

## â‘  **ì„¤ëª… ì„¹ì…˜ (ìì—°ì–´ ì„¤ëª…)**    
- 3~5ì¤„ ì´ë‚´  
- "ì•„ë˜ í‘œëŠ” ì‚¬ìš©ìì˜ ì¬ë¬´ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì•¡ê³µì œ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤."  
  ì™€ ê°™ì€ í˜•íƒœì˜ ìš”ì•½ ì„¤ëª…  
- ë¶ˆí•„ìš”í•œ ë¬¸ì¥ ê¸ˆì§€  
- ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ì§€ë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…  

---

## â‘¡ **Markdown í‘œ í˜•ì‹ ê²°ê³¼**

ë°˜ë“œì‹œ ë‹¤ìŒ í‘œ êµ¬ì¡°ë¥¼ ìœ ì§€:

| í•­ëª© | ê°€ëŠ¥ ì—¬ë¶€ | ì´ìœ  |
|------|-----------|------|
| í•­ëª©ëª… | âœ”ï¸  / âŒ | 100ì ì´ë‚´ ì´ìœ  |

- "ê°€ëŠ¥ ì—¬ë¶€"ëŠ” ë°˜ë“œì‹œ **âœ”ï¸** ë˜ëŠ” **âŒ**  
- ì´ìœ ëŠ” ë°˜ë“œì‹œ **100ì ì´ë‚´**  
- ë°ì´í„° ì—†ëŠ” í•­ëª©ì€ â€œë¬¸ì„œì— ê´€ë ¨ í•­ëª© ì—†ìŒâ€ì²˜ëŸ¼ ëª…í™•íˆ í‘œí˜„  

---

# â— ì ˆëŒ€ ê¸ˆì§€ ê·œì¹™
- í‘œ ì™¸ì˜ ë¶ˆí•„ìš”í•œ ë¬¸ë‹¨ ì¶”ê°€ ê¸ˆì§€
- í‘œ ì•„ë˜ì— ì„¤ëª… ì¶”ê°€ ê¸ˆì§€
- ì£¼ê´€ì  ì¡°ì–¸ ë˜ëŠ” ì¶”ê°€ ì§ˆë¬¸ ê¸ˆì§€
- ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ â€œì„¤ëª… â†’ í‘œâ€ ìˆœì„œ

---

ìœ„ ì§€ì¹¨ì„ 100% ì¤€ìˆ˜í•˜ì—¬ â€œì„¤ëª… ì„¹ì…˜ + ë§ˆí¬ë‹¤ìš´ í‘œâ€ ë‘ ê°€ì§€ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.

"""

        answer = await qa_on_document(
            data_str,
            question,
            "ì¶œë ¥ì€ ë°˜ë“œì‹œ â€œì„¤ëª… ì„¹ì…˜ + ë§ˆí¬ë‹¤ìš´ í‘œâ€ í˜•íƒœë¡œë§Œ ì‘ì„±í•˜ë¼."
        )

        # ğŸ”¥ ìºì‹œ ì €ì¥ (24ì‹œê°„)
        AICache.set_cached_response(cache_key, answer, ttl=86400)

        return answer

    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


# -----------------------
# ìºì‹œ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
# -----------------------
@documents_multi_agents_router.get("/cache/stats")
@log_util.logging_decorator
async def get_cache_stats(session_id: str = Depends(get_current_user)):
    """ìºì‹œ í†µê³„ ì¡°íšŒ"""
    try:
        stats = AICache.get_cache_stats()
        return {
            "success": True,
            "stats": stats
        }
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")


@documents_multi_agents_router.delete("/cache/clear")
@log_util.logging_decorator
async def clear_user_cache(session_id: str = Depends(get_current_user)):
    """ì‚¬ìš©ìì˜ ëª¨ë“  ìºì‹œ ì‚­ì œ"""
    try:
        deleted_count = AICache.invalidate_user_cache(session_id)
        return {
            "success": True,
            "message": f"{deleted_count}ê°œì˜ ìºì‹œ í•­ëª©ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "deleted_count": deleted_count
        }
    except Exception as e:
        raise HTTPException(500, f"{type(e).__name__}: {str(e)}")
